import torch
import pandas as pd
from torch import nn
from torch.utils.data import DataLoader, Subset
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from transformers import AutoTokenizer
import torchvision.models as models
from tqdm import tqdm
from sklearn.metrics import accuracy_score, classification_report

from utils.TADataset import TADataset   # ä½ çš„ dataset ä¿æŒä¸å˜


# ==============================
# ğŸ”¥ ImageEncoderï¼šå·²æ•´åˆè¿›æœ¬æ–‡ä»¶
# ==============================
class ImageEncoder(nn.Module):
    def __init__(self, backbone="resnet18", pretrained=True, out_dim=256):
        super().__init__()

        if backbone == "resnet18":
            model = models.resnet18(weights="IMAGENET1K_V1" if pretrained else None)
            in_features = 512
        elif backbone == "resnet50":
            model = models.resnet50(weights="IMAGENET1K_V1" if pretrained else None)
            in_features = 2048
        else:
            raise ValueError("Unsupported backbone:", backbone)

        # å»æ‰åŸå§‹åˆ†ç±»å¤´
        self.encoder = nn.Sequential(*list(model.children())[:-1])  # â†’ shape [B, C, 1, 1]
        self.fc = nn.Linear(in_features, out_dim)

    def forward(self, x):
        x = self.encoder(x)
        x = x.flatten(1)
        x = self.fc(x)
        return x  # shape [B, out_dim]


# ==============================
# ğŸ”¥ å•æ¨¡æ€å›¾åƒåˆ†ç±»æ¨¡å‹
# ==============================
class ImageClassifier(nn.Module):
    def __init__(self, img_backbone="resnet18", img_dim=256, num_labels=3):
        super().__init__()
        self.img_encoder = ImageEncoder(backbone=img_backbone, out_dim=img_dim)
        self.classifier = nn.Linear(img_dim, num_labels)

    def forward(self, head_img):
        img_feat = self.img_encoder(head_img)
        logits = self.classifier(img_feat)
        return logits


# ==============================
# ğŸ”¥ ä¸»è®­ç»ƒç¨‹åºï¼ˆå¯ç›´æ¥è¿è¡Œï¼‰
# ==============================
if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # ======= å‚æ•° =======
    bert_path = "/home/yanshuyu/Data/AID/TAK/Bio_ClinicalBERT"
    excel_path = "/home/yanshuyu/Data/AID/all.xlsx"
    tokenizer = AutoTokenizer.from_pretrained(bert_path)

    max_length = 384
    num_epochs = 50
    lr = 1e-4
    batch_size = 4

    # ======= è¯»å– Excel =======
    df = pd.read_excel(excel_path, sheet_name="effect1")

    label_col = df.columns[-1]
    labels = df[label_col].values
    report = df["mra_examination_re_des_1"].astype(str).tolist()

    # æ ‡ç­¾ç¼–ç 
    label_encoder = LabelEncoder()
    y = label_encoder.fit_transform(labels)
    num_labels = len(label_encoder.classes_)

    # tabular æ•°æ®ï¼ˆä¸ç”¨äºå›¾åƒæ¨¡å‹ï¼Œåªç”¨äº dataset å¯¹é½ï¼‰
    X = df.select_dtypes(include=["int64", "float64"])
    X = X.drop(columns=[label_col], errors="ignore")
    X = SimpleImputer(strategy="mean").fit_transform(X)
    X = StandardScaler().fit_transform(X)

    # åˆ’åˆ†æ•°æ®
    train_idx, val_idx = train_test_split(
        range(len(df)),
        test_size=0.2,
        random_state=42,
        stratify=y
    )

    # åˆ›å»º Dataset / Loader
    data = TADataset(df, report, X, y, tokenizer, max_length)
    train_loader = DataLoader(Subset(data, train_idx), batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(Subset(data, val_idx), batch_size=batch_size, shuffle=False)

    # ======= åˆå§‹åŒ–æ¨¡å‹ =======
    model = ImageClassifier(
        img_backbone="resnet18",     # â† å¯æ”¹æˆ resnet50
        img_dim=256,
        num_labels=num_labels
    ).to(device)

    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()

    # ==============================
    # ğŸ”¥ è®­ç»ƒå¾ªç¯
    # ==============================
    for epoch in range(num_epochs):

        model.train()
        total_loss = 0

        for batch in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} [Train]"):
            head = batch["head"].to(device)      # â† å•æ¨¡æ€ï¼šåªç”¨å›¾åƒ
            label = batch["label"].to(device)

            optimizer.zero_grad()
            logits = model(head)
            loss = criterion(logits, label)

            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        avg_loss = total_loss / len(train_loader)
        print(f"\nEpoch {epoch+1} Train Loss: {avg_loss:.4f}")

        # ==============================
        # ğŸ”¥ éªŒè¯ + classification report
        # ==============================
        model.eval()
        preds, trues = [], []

        with torch.no_grad():
            for batch in val_loader:
                head = batch["head"].to(device)
                label = batch["label"].to(device)

                logits = model(head)
                pred = torch.argmax(logits, dim=1)

                preds.extend(pred.cpu().numpy())
                trues.extend(label.cpu().numpy())

        acc = accuracy_score(trues, preds)
        print(f"Epoch {epoch + 1} Val ACC: {acc:.4f}")

        # å…³é”®ä¿®å¤ï¼šæŠŠ target_names è½¬å­—ç¬¦ä¸²
        target_names = [str(c) for c in label_encoder.classes_]

        print(classification_report(
            trues,
            preds,
            target_names=target_names,
            digits=3
        ))
        save_path = "/home/yanshuyu/Data/AID/TAK/best_model/"
        sp = save_path + str(epoch) + '.pt'
        torch.save(model.state_dict(), sp)

